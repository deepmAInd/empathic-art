{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empathic Art- SVM modeling\n",
    "by Mickey Krekels \n",
    "\n",
    "## Loading imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "# import os \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# import librosa\n",
    "import cv2\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import PIL \n",
    "# this is needed for loading large images dataset \n",
    "import PIL \n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "# import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "#import os\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "This dataset is a combination of Dataset:\n",
    "\n",
    "- [Toronto emotional speech set (TESS) - Older talker_Happy](https://tspace.library.utoronto.ca/handle/1807/24501)<br>\n",
    "Author:<br>\n",
    "Dupuis, Kate; Pichora-Fuller, M. Kathleen\n",
    "- [The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976#.Y0e8o3ZBy3C)<br>\n",
    "Author:<br>\n",
    "Livingstone, Steven R., & Russo, Frank A.\n",
    "- [The variably intense vocalizations of affect and emotion (VIVAE)](https://pubmed.ncbi.nlm.nih.gov/35129996/)<br>\n",
    "Author:<br>\n",
    "Natalie Holz, Pauline Larrouy-Maestri, David Poeppel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = {\n",
    "    \"Vivae\": \"../../data/VIVAE/core_set/\", \n",
    "    \"Ravdess\": \"../../data/RAVDESS/Audio_Speech_Actors/\", \n",
    "    \"Tess\": \"../../data/utoronto/data\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Dataframe</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Word</th>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S04_fear_peak_03.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Fear</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S09_pleasure_strong_08.wav</td>\n",
       "      <td>S09</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S07_pleasure_peak_07.wav</td>\n",
       "      <td>S07</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S04_pain_strong_08.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Pain</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S04_fear_strong_05.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Fear</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S08_pain_peak_01.wav</td>\n",
       "      <td>S08</td>\n",
       "      <td>Pain</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.536463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S06_fear_moderate_03.wav</td>\n",
       "      <td>S06</td>\n",
       "      <td>Fear</td>\n",
       "      <td>moderate</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S09_pain_moderate_09.wav</td>\n",
       "      <td>S09</td>\n",
       "      <td>Pain</td>\n",
       "      <td>moderate</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S01_pain_moderate_04.wav</td>\n",
       "      <td>S01</td>\n",
       "      <td>Pain</td>\n",
       "      <td>moderate</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.536463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S07_surprise_strong_01.wav</td>\n",
       "      <td>S07</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.989025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_name Speaker   Emotion Intensity Dataframe  Duration  \\\n",
       "0        S04_fear_peak_03.wav     S04      Fear      peak     VIVAE  0.752472   \n",
       "1  S09_pleasure_strong_08.wav     S09  Pleasure    strong     VIVAE  0.752472   \n",
       "2    S07_pleasure_peak_07.wav     S07  Pleasure      peak     VIVAE  0.672404   \n",
       "3      S04_pain_strong_08.wav     S04      Pain    strong     VIVAE  0.752472   \n",
       "4      S04_fear_strong_05.wav     S04      Fear    strong     VIVAE  0.672404   \n",
       "5        S08_pain_peak_01.wav     S08      Pain      peak     VIVAE  0.536463   \n",
       "6    S06_fear_moderate_03.wav     S06      Fear  moderate     VIVAE  0.752472   \n",
       "7    S09_pain_moderate_09.wav     S09      Pain  moderate     VIVAE  0.672404   \n",
       "8    S01_pain_moderate_04.wav     S01      Pain  moderate     VIVAE  0.536463   \n",
       "9  S07_surprise_strong_01.wav     S07  Surprise    strong     VIVAE  0.989025   \n",
       "\n",
       "  Word   Type Gender  \n",
       "0  NaN  Sound    NaN  \n",
       "1  NaN  Sound    NaN  \n",
       "2  NaN  Sound    NaN  \n",
       "3  NaN  Sound    NaN  \n",
       "4  NaN  Sound    NaN  \n",
       "5  NaN  Sound    NaN  \n",
       "6  NaN  Sound    NaN  \n",
       "7  NaN  Sound    NaN  \n",
       "8  NaN  Sound    NaN  \n",
       "9  NaN  Sound    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = \"../../data/merged_data.csv\"\n",
    "df = open(merged_data, \"r\")\n",
    "df = pd.read_csv(df)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this modeling phase were only interested in the columns filename and Emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the audio files to Mel-spectograms and saving the result locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Dataframe</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Word</th>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S04_fear_peak_03.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Fear</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S09_pleasure_strong_08.wav</td>\n",
       "      <td>S09</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S07_pleasure_peak_07.wav</td>\n",
       "      <td>S07</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S04_pain_strong_08.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Pain</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S04_fear_strong_05.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Fear</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>S05_pleasure_moderate_10.wav</td>\n",
       "      <td>S05</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>moderate</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.505011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>S08_surprise_moderate_07.wav</td>\n",
       "      <td>S08</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>moderate</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>1.158889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>S05_surprise_low_02.wav</td>\n",
       "      <td>S05</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>low</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>1.880295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>S09_pleasure_peak_102.wav</td>\n",
       "      <td>S09</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.837800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>S03_pain_low_09.wav</td>\n",
       "      <td>S03</td>\n",
       "      <td>Pain</td>\n",
       "      <td>low</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.805351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file_name Speaker   Emotion Intensity Dataframe  \\\n",
       "0            S04_fear_peak_03.wav     S04      Fear      peak     VIVAE   \n",
       "1      S09_pleasure_strong_08.wav     S09  Pleasure    strong     VIVAE   \n",
       "2        S07_pleasure_peak_07.wav     S07  Pleasure      peak     VIVAE   \n",
       "3          S04_pain_strong_08.wav     S04      Pain    strong     VIVAE   \n",
       "4          S04_fear_strong_05.wav     S04      Fear    strong     VIVAE   \n",
       "..                            ...     ...       ...       ...       ...   \n",
       "475  S05_pleasure_moderate_10.wav     S05  Pleasure  moderate     VIVAE   \n",
       "476  S08_surprise_moderate_07.wav     S08  Surprise  moderate     VIVAE   \n",
       "477       S05_surprise_low_02.wav     S05  Surprise       low     VIVAE   \n",
       "478     S09_pleasure_peak_102.wav     S09  Pleasure      peak     VIVAE   \n",
       "479           S03_pain_low_09.wav     S03      Pain       low     VIVAE   \n",
       "\n",
       "     Duration Word   Type Gender  \n",
       "0    0.752472  NaN  Sound    NaN  \n",
       "1    0.752472  NaN  Sound    NaN  \n",
       "2    0.672404  NaN  Sound    NaN  \n",
       "3    0.752472  NaN  Sound    NaN  \n",
       "4    0.672404  NaN  Sound    NaN  \n",
       "..        ...  ...    ...    ...  \n",
       "475  0.505011  NaN  Sound    NaN  \n",
       "476  1.158889  NaN  Sound    NaN  \n",
       "477  1.880295  NaN  Sound    NaN  \n",
       "478  0.837800  NaN  Sound    NaN  \n",
       "479  0.805351  NaN  Sound    NaN  \n",
       "\n",
       "[480 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vivae_df = df.loc[df[\"Dataframe\"] == \"VIVAE\"]\n",
    "vivae_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_path = \"C:/Users/micke/Desktop/Fontys/S7/Group_project/dataset_merged_local_save/\"\n",
    "\n",
    "audio_file_path_list = []\n",
    "\n",
    "vivae_df = df[df[\"Dataframe\"] == \"VIVAE\"]\n",
    "tess_df = df[df[\"Dataframe\"] == \"TESS\"]\n",
    "# ravedess_df = df[df[\"Dataframe\"] == \"RAVEDESS\"]\n",
    "\n",
    "\n",
    "for index, row in vivae_df.iterrows():\n",
    "    audio_file_path_list.append(audio_data[\"Vivae\"] + \"/\" + row[\"file_name\"])\n",
    "\n",
    "for index, row in tess_df.iterrows():\n",
    "    audio_file_path_list.append(audio_data[\"Tess\"] + \"/\" + row[\"file_name\"])\n",
    "\n",
    "# for index, row in ravedess_df.iterrows():\n",
    "\n",
    "#     path = audio_data[\"Ravdess\"]+ \"Actor_\" + \"/\" + row[\"file_name\"]\n",
    "#     audio_file_path_list.append(audio_data[\"Ravdess\"] + \"/\" + row[\"file_name\"])\n",
    "\n",
    "# for filename in os.listdir(audio_data[\"Ravdess\"]):\n",
    "#     f = os.path.join(audio_data[\"Ravdess\"], filename)\n",
    "#     # checking if it is a file\n",
    "\n",
    "\n",
    "\n",
    "len(audio_file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Dataframe</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Word</th>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>sound_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S04_fear_peak_03.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Fear</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/VIVAE/core_set//S04_fear_peak_03.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S09_pleasure_strong_08.wav</td>\n",
       "      <td>S09</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/VIVAE/core_set//S09_pleasure_strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S07_pleasure_peak_07.wav</td>\n",
       "      <td>S07</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>peak</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/VIVAE/core_set//S07_pleasure_peak_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S04_pain_strong_08.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Pain</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.752472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/VIVAE/core_set//S04_pain_strong_08.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S04_fear_strong_05.wav</td>\n",
       "      <td>S04</td>\n",
       "      <td>Fear</td>\n",
       "      <td>strong</td>\n",
       "      <td>VIVAE</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/VIVAE/core_set//S04_fear_strong_05.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>YAF_tough_happy.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>1.866019</td>\n",
       "      <td>tough</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_tough_happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>OAF_nice_angry.wav</td>\n",
       "      <td>OAF</td>\n",
       "      <td>angry</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.275907</td>\n",
       "      <td>nice</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/OAF_nice_angry.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>YAF_gap_ps.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>ps</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>1.652535</td>\n",
       "      <td>gap</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_gap_ps.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>OAF_phone_fear.wav</td>\n",
       "      <td>OAF</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.189645</td>\n",
       "      <td>phone</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/OAF_phone_fear.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>OAF_soup_neutral.wav</td>\n",
       "      <td>OAF</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.020111</td>\n",
       "      <td>soup</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/OAF_soup_neutral.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3280 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_name Speaker   Emotion Intensity Dataframe  \\\n",
       "0           S04_fear_peak_03.wav     S04      Fear      peak     VIVAE   \n",
       "1     S09_pleasure_strong_08.wav     S09  Pleasure    strong     VIVAE   \n",
       "2       S07_pleasure_peak_07.wav     S07  Pleasure      peak     VIVAE   \n",
       "3         S04_pain_strong_08.wav     S04      Pain    strong     VIVAE   \n",
       "4         S04_fear_strong_05.wav     S04      Fear    strong     VIVAE   \n",
       "...                          ...     ...       ...       ...       ...   \n",
       "3275         YAF_tough_happy.wav     YAF     Happy  Moderate      TESS   \n",
       "3276          OAF_nice_angry.wav     OAF     angry  Moderate      TESS   \n",
       "3277              YAF_gap_ps.wav     YAF        ps  Moderate      TESS   \n",
       "3278          OAF_phone_fear.wav     OAF      Fear  Moderate      TESS   \n",
       "3279        OAF_soup_neutral.wav     OAF      Calm  Moderate      TESS   \n",
       "\n",
       "      Duration   Word       Type Gender  \\\n",
       "0     0.752472    NaN      Sound    NaN   \n",
       "1     0.752472    NaN      Sound    NaN   \n",
       "2     0.672404    NaN      Sound    NaN   \n",
       "3     0.752472    NaN      Sound    NaN   \n",
       "4     0.672404    NaN      Sound    NaN   \n",
       "...        ...    ...        ...    ...   \n",
       "3275  1.866019  tough  Non-Sound    NaN   \n",
       "3276  2.275907   nice  Non-Sound    NaN   \n",
       "3277  1.652535    gap  Non-Sound    NaN   \n",
       "3278  2.189645  phone  Non-Sound    NaN   \n",
       "3279  2.020111   soup  Non-Sound    NaN   \n",
       "\n",
       "                                             sound_path  \n",
       "0       ../../data/VIVAE/core_set//S04_fear_peak_03.wav  \n",
       "1     ../../data/VIVAE/core_set//S09_pleasure_strong...  \n",
       "2     ../../data/VIVAE/core_set//S07_pleasure_peak_0...  \n",
       "3     ../../data/VIVAE/core_set//S04_pain_strong_08.wav  \n",
       "4     ../../data/VIVAE/core_set//S04_fear_strong_05.wav  \n",
       "...                                                 ...  \n",
       "3275       ../../data/utoronto/data/YAF_tough_happy.wav  \n",
       "3276        ../../data/utoronto/data/OAF_nice_angry.wav  \n",
       "3277            ../../data/utoronto/data/YAF_gap_ps.wav  \n",
       "3278        ../../data/utoronto/data/OAF_phone_fear.wav  \n",
       "3279      ../../data/utoronto/data/OAF_soup_neutral.wav  \n",
       "\n",
       "[3280 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [vivae_df, tess_df]\n",
    "df = pd.concat(frames)\n",
    "df[\"sound_path\"] = audio_file_path_list\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the sound files to mel-spectrograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in df.iterrows():\n",
    "#     # load audio file\n",
    "#     path = row[\"sound_path\"]\n",
    "#     x, sr = librosa.load(path, sr=44100)\n",
    "#     # compute mel-spectrogram\n",
    "#     melspectrum = librosa.feature.melspectrogram(y=x, sr=sr, hop_length= 512, window='hann', n_mels=256)\n",
    "#     # convert to decibels\n",
    "#     S_dB = librosa.power_to_db(melspectrum, ref=np.max)\n",
    "#     # convert plot to image\n",
    "#     img = librosa.display.specshow(S_dB)\n",
    "#     # save image to disk\n",
    "#     img.figure.savefig(saving_path + \"/\"+ row['file_name'] +'.png')\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = []\n",
    "for index, row in df.iterrows():\n",
    "    image_path_list.append(saving_path + \"/\"+ row['file_name'] +'.png')\n",
    "\n",
    "df[\"image_path\"] = image_path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to Tensorflow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fear' 'Pleasure' 'Pain' 'Surprise' 'Angry' 'Achievement' 'Calm' 'Sad'\n",
      " 'Happy' 'ps' 'Disgust' 'angry']\n"
     ]
    }
   ],
   "source": [
    "class_names = df[\"Emotion\"].unique()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fear' 'Pleasure' 'Pain' 'Surprise' 'Angry' 'Achievement' 'Calm' 'Sad'\n",
      " 'Happy' 'Disgust']\n"
     ]
    }
   ],
   "source": [
    "#remane Emotion value ps to suprise\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace(\"ps\", \"Surprise\")\n",
    "df[\"Emotion\"] = df[\"Emotion\"].replace(\"angry\", \"Angry\")\n",
    "class_names = df[\"Emotion\"].unique()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fear           480\n",
       "Surprise       480\n",
       "Angry          480\n",
       "Calm           400\n",
       "Sad            400\n",
       "Happy          400\n",
       "Disgust        400\n",
       "Pleasure        80\n",
       "Pain            80\n",
       "Achievement     80\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count = df['Emotion'].value_counts()\n",
    "unique_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values **Pleasure, Pain and Achievement** are not going to be used for this model. There are only 80 labels aviable and that is not enough for training a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fear        480\n",
       "Surprise    480\n",
       "Angry       480\n",
       "Calm        400\n",
       "Sad         400\n",
       "Happy       400\n",
       "Disgust     400\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df[\"Emotion\"] != 'Pleasure' ]\n",
    "df = df.loc[df[\"Emotion\"] != 'Pain' ]\n",
    "df = df.loc[df[\"Emotion\"] != 'Achievement' ]\n",
    "\n",
    "unique_count = df['Emotion'].value_counts()\n",
    "unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fear', 'Surprise', 'Angry', 'Calm', 'Sad', 'Happy', 'Disgust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = df[\"Emotion\"].unique()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total we have 7 label types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where using this helper function below to save the spectogram into there correct folders\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensorflow_dataset(copy_dir,df,labels):\n",
    "    dfs = []\n",
    "\n",
    "    for label in labels:\n",
    "        dfs.append(df[df['Emotion'] == label])\n",
    "\n",
    "    for df_split in dfs:\n",
    "\n",
    "        for index, row in df_split.iterrows():\n",
    "            label = row['Emotion']\n",
    "            path = row['image_path']\n",
    "            shutil.copy(path, copy_dir + label + \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Dataframe</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Word</th>\n",
       "      <th>Type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>sound_path</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAF_cause_angry.wav</td>\n",
       "      <td>OAF</td>\n",
       "      <td>Angry</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.293274</td>\n",
       "      <td>cause</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/OAF_cause_angry.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAF_bite_angry.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Angry</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>1.704473</td>\n",
       "      <td>bite</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_bite_angry.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAF_reach_neutral.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.281887</td>\n",
       "      <td>reach</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_reach_neutral.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAF_moon_disgust.wav</td>\n",
       "      <td>OAF</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>1.652535</td>\n",
       "      <td>moon</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/OAF_moon_disgust.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YAF_hire_fear.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.200172</td>\n",
       "      <td>hire</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_hire_fear.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>YAF_jug_neutral.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.275907</td>\n",
       "      <td>jug</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_jug_neutral.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>YAF_lease_angry.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Angry</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.051159</td>\n",
       "      <td>lease</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_lease_angry.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>YAF_youth_fear.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>1.939215</td>\n",
       "      <td>youth</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_youth_fear.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>OAF_rain_sad.wav</td>\n",
       "      <td>OAF</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>2.714017</td>\n",
       "      <td>rain</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/OAF_rain_sad.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>YAF_jug_angry.wav</td>\n",
       "      <td>YAF</td>\n",
       "      <td>Angry</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>TESS</td>\n",
       "      <td>1.813345</td>\n",
       "      <td>jug</td>\n",
       "      <td>Non-Sound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../../data/utoronto/data/YAF_jug_angry.wav</td>\n",
       "      <td>C:/Users/micke/Desktop/Fontys/S7/Group_project...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3040 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name Speaker  Emotion Intensity Dataframe  Duration  \\\n",
       "0       OAF_cause_angry.wav     OAF    Angry  Moderate      TESS  2.293274   \n",
       "1        YAF_bite_angry.wav     YAF    Angry  Moderate      TESS  1.704473   \n",
       "2     YAF_reach_neutral.wav     YAF     Calm  Moderate      TESS  2.281887   \n",
       "3      OAF_moon_disgust.wav     OAF  Disgust  Moderate      TESS  1.652535   \n",
       "4         YAF_hire_fear.wav     YAF     Fear  Moderate      TESS  2.200172   \n",
       "...                     ...     ...      ...       ...       ...       ...   \n",
       "3035    YAF_jug_neutral.wav     YAF     Calm  Moderate      TESS  2.275907   \n",
       "3036    YAF_lease_angry.wav     YAF    Angry  Moderate      TESS  2.051159   \n",
       "3037     YAF_youth_fear.wav     YAF     Fear  Moderate      TESS  1.939215   \n",
       "3038       OAF_rain_sad.wav     OAF      Sad  Moderate      TESS  2.714017   \n",
       "3039      YAF_jug_angry.wav     YAF    Angry  Moderate      TESS  1.813345   \n",
       "\n",
       "       Word       Type Gender                                      sound_path  \\\n",
       "0     cause  Non-Sound    NaN    ../../data/utoronto/data/OAF_cause_angry.wav   \n",
       "1      bite  Non-Sound    NaN     ../../data/utoronto/data/YAF_bite_angry.wav   \n",
       "2     reach  Non-Sound    NaN  ../../data/utoronto/data/YAF_reach_neutral.wav   \n",
       "3      moon  Non-Sound    NaN   ../../data/utoronto/data/OAF_moon_disgust.wav   \n",
       "4      hire  Non-Sound    NaN      ../../data/utoronto/data/YAF_hire_fear.wav   \n",
       "...     ...        ...    ...                                             ...   \n",
       "3035    jug  Non-Sound    NaN    ../../data/utoronto/data/YAF_jug_neutral.wav   \n",
       "3036  lease  Non-Sound    NaN    ../../data/utoronto/data/YAF_lease_angry.wav   \n",
       "3037  youth  Non-Sound    NaN     ../../data/utoronto/data/YAF_youth_fear.wav   \n",
       "3038   rain  Non-Sound    NaN       ../../data/utoronto/data/OAF_rain_sad.wav   \n",
       "3039    jug  Non-Sound    NaN      ../../data/utoronto/data/YAF_jug_angry.wav   \n",
       "\n",
       "                                             image_path  \n",
       "0     C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "1     C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "2     C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "3     C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "4     C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "...                                                 ...  \n",
       "3035  C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "3036  C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "3037  C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "3038  C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "3039  C:/Users/micke/Desktop/Fontys/S7/Group_project...  \n",
       "\n",
       "[3040 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a test and train set RNN model (split of 80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:int(len(df)*0.8)]\n",
    "test  = df[int(len(df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"Emotion\"].unique()\n",
    "tensorflow_data_path = \"C:/Users/micke/Desktop/Fontys/S7/Group_project/\"\n",
    "\n",
    "# df_to_tensorflow_dataset(tensorflow_data_path +'input/training/',train,labels)\n",
    "# df_to_tensorflow_dataset(tensorflow_data_path +'input/validation/',test,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2432 files belonging to 7 classes.\n",
      "Using 1946 files for training.\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(tensorflow_data_path + 'input/training/')\n",
    "\n",
    "image_size = cv2.imread(df.image_path[0]).shape\n",
    "\n",
    "batch_size = 32\n",
    "img_height = image_size[0]\n",
    "img_width = image_size[1]\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2432 files belonging to 7 classes.\n",
      "Using 486 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_len = len(class_names)\n",
    "\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', strides=2, input_shape=[img_height, img_width, 3]))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Step 5 - Output Layer\n",
    "# cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "## For Binary Classification\n",
    "cnn.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='linear')) #\n",
    "## for mulitclassification\n",
    "cnn.add(tf.keras.layers.Dense(class_len, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='softmax'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'squared_hinge', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 144, 216, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 72, 108, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 72, 108, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 36, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 62208)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               7962752   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 14        \n",
      "=================================================================\n",
      "Total params: 7,973,039\n",
      "Trainable params: 7,973,039\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "61/61 [==============================] - 20s 326ms/step - loss: 0.8936 - accuracy: 0.1521 - val_loss: 0.8904 - val_accuracy: 0.1543\n",
      "Epoch 2/15\n",
      "61/61 [==============================] - 19s 308ms/step - loss: 0.8874 - accuracy: 0.1521 - val_loss: 0.8864 - val_accuracy: 0.1543\n",
      "Epoch 3/15\n",
      "61/61 [==============================] - 19s 308ms/step - loss: 0.8846 - accuracy: 0.1521 - val_loss: 0.8845 - val_accuracy: 0.1543\n",
      "Epoch 4/15\n",
      "61/61 [==============================] - 19s 317ms/step - loss: 0.8831 - accuracy: 0.1521 - val_loss: 0.8833 - val_accuracy: 0.1543\n",
      "Epoch 5/15\n",
      "61/61 [==============================] - 19s 310ms/step - loss: 0.8821 - accuracy: 0.1572 - val_loss: 0.8826 - val_accuracy: 0.1667\n",
      "Epoch 6/15\n",
      "61/61 [==============================] - 18s 302ms/step - loss: 0.5916 - accuracy: 0.1624 - val_loss: 0.5820 - val_accuracy: 0.1399\n",
      "Epoch 7/15\n",
      "61/61 [==============================] - 19s 309ms/step - loss: 0.5727 - accuracy: 0.1619 - val_loss: 0.5818 - val_accuracy: 0.1399\n",
      "Epoch 8/15\n",
      "61/61 [==============================] - 19s 309ms/step - loss: 0.5725 - accuracy: 0.1619 - val_loss: 0.5816 - val_accuracy: 0.1399\n",
      "Epoch 9/15\n",
      "61/61 [==============================] - 18s 303ms/step - loss: 0.5724 - accuracy: 0.1619 - val_loss: 0.5815 - val_accuracy: 0.1399\n",
      "Epoch 10/15\n",
      "61/61 [==============================] - 19s 304ms/step - loss: 0.5722 - accuracy: 0.1619 - val_loss: 0.5814 - val_accuracy: 0.1399\n",
      "Epoch 11/15\n",
      "61/61 [==============================] - 20s 322ms/step - loss: 0.5721 - accuracy: 0.1619 - val_loss: 0.5813 - val_accuracy: 0.1399\n",
      "Epoch 12/15\n",
      "61/61 [==============================] - 20s 323ms/step - loss: 0.5721 - accuracy: 0.1619 - val_loss: 0.5812 - val_accuracy: 0.1399\n",
      "Epoch 13/15\n",
      "61/61 [==============================] - 19s 307ms/step - loss: 0.5720 - accuracy: 0.1619 - val_loss: 0.5811 - val_accuracy: 0.1399\n",
      "Epoch 14/15\n",
      "61/61 [==============================] - 19s 309ms/step - loss: 0.5719 - accuracy: 0.1619 - val_loss: 0.5811 - val_accuracy: 0.1399\n",
      "Epoch 15/15\n",
      "61/61 [==============================] - 19s 308ms/step - loss: 0.5719 - accuracy: 0.1619 - val_loss: 0.5810 - val_accuracy: 0.1399\n"
     ]
    }
   ],
   "source": [
    "# Compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'hinge', metrics = ['accuracy'])\n",
    "\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "r=cnn.fit(x = train_ds, validation_data = val_ds, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlDUlEQVR4nO3de3SV9Z3v8fc3CRAh2dxvSUDwgnKTW6B0LLaj1YKj6Gml1upM7fTo6VI702Nrpc6MY/W0Y2t7OtMpnYrWquvYMi6s42VQ1BZKO+KUgAhyK4gkbK4BIYSb5PI9fzw76SbsJDu3/Txhf15rZe29n8vv+W5I9nf/fs/vYu6OiIhkn5ywAxARkXAoAYiIZCklABGRLKUEICKSpZQARESyVF7YAbTFoEGDfNSoUWGHISLSraxevfqAuw9uur1bJYBRo0ZRVlYWdhgiIt2KmZWn2q4mIBGRLKUEICKSpZQARESyVLe6ByAiZ7+amhri8TgnT54MO5RuJz8/n5KSEnr06JHW8UoAIhIp8XicwsJCRo0ahZmFHU634e4cPHiQeDzO6NGj0zpHTUAiEiknT55k4MCB+vBvIzNj4MCBbao5KQGISOTow7992vrvpgQgHRNfDXGNzRDpjpQApGNeuBNeuTfsKEQ6zeHDh/nJT37SrnOvvvpqDh8+3LkBdSElAGm/4x9A5SY4sivsSEQ6TUsJoLa2tsVzlyxZQr9+/bogqq6hBCDtV7EyeKzeC3U14cYi0knmz5/Pe++9x+TJk7nnnntYvnw5s2bNYu7cuYwbNw6A66+/nmnTpjF+/HgWLlzYeO6oUaM4cOAAO3bsYOzYsdx2222MHz+eq666ihMnTpxxrZdeeomPfOQjTJkyhU9+8pPs27cPgKNHj/LFL36RiRMncskll/Dcc88B8OqrrzJ16lQmTZrEFVdc0eH3qm6g0n7lbyaeeJAE+o0INRw5+3zrpQ1s3H2kU8scVxTjH68d3+z+hx9+mHfffZe1a9cCsHz5ctasWcO7777b2L3yiSeeYMCAAZw4cYLp06fzmc98hoEDB55WztatW/nlL3/JY489xmc/+1mee+45brnlltOO+djHPsZbb72FmfH444/zve99jx/84Ac89NBD9O3bl/Xr1wNw6NAhKisrue2221ixYgWjR4/mgw8+6PC/hRKAtF/FSsjpAfU1cGS3EoCctWbMmHFa3/of/ehHPP/88wDs3LmTrVu3npEARo8ezeTJkwGYNm0aO3bsOKPceDzOjTfeyJ49ezh16lTjNd544w0WLVrUeFz//v156aWXuOyyyxqPGTBgQIfflxKAtM+pY7DnHbjgk/DHV3UfQLpES9/UM6lPnz6Nz5cvX84bb7zBypUr6d27N5/4xCdS9r3v1atX4/Pc3NyUTUBf+cpXuPvuu5k7dy7Lly/ngQce6JL4m6N7ANI+8VVQXwsTbgheH9kdbjwinaSwsJDq6upm91dVVdG/f3969+7N5s2beeutt9p9raqqKoqLiwF46qmnGrdfeeWVLFiwoPH1oUOHmDlzJitWrOD9998H6JQmICUAaZ/ylYDBmKugR28lADlrDBw4kEsvvZQJEyZwzz33nLF/9uzZ1NbWMnbsWObPn8/MmTPbfa0HHniAefPmMW3aNAYNGtS4/e///u85dOgQEyZMYNKkSSxbtozBgwezcOFCPv3pTzNp0iRuvPHGdl+3gbl7hwvJlNLSUteCMBHx1LVw4hB8+ffwr6UwdDx89qnWzxNpxaZNmxg7dmzYYXRbqf79zGy1u5c2PTatGoCZzTazLWa2zczmp9h/mZmtMbNaM7uhyb6RZvaamW0ys41mNiqx/Ukze9/M1iZ+JrfhPUqY6mqC0b8j/yx4HSvSPQCRbqjVBGBmucACYA4wDrjJzMY1OawCuBX4RYoingYecfexwAxgf9K+e9x9cuJnbdvDl1DseQdqjsO5Hw1ex4rVBCTSDaXTC2gGsM3dtwOY2SLgOmBjwwHuviOxrz75xESiyHP31xPHHe2csCVUDf3/k2sA1XuhrhZy1bFMpLtIpwmoGNiZ9Dqe2JaOMcBhM/uVmb1tZo8kahQNvm1m68zsh2bWq7lCJGIqVsKA86BwaPA6VgReB8f2t3yeiERKV/cCygNmAV8HpgPnETQVAXwTuDixfQCQckYxM7vdzMrMrKyysrKLw5VW1dcHCaDh2z8ETUCgZiCRbiadBLALSB7iWZLYlo44sNbdt7t7LfAfwFQAd9/jgQ+BnxM0NZ3B3Re6e6m7lw4ePDjNy0qXObAl6P3T0P4PQQ0AdCNYpJtJJwGsAi40s9Fm1hP4HPBimuWvAvqZWcMn9+Uk7h2Y2fDEowHXA++2IW4JS2P7f1IC6FsSPKoGIFmqoKAg7BDapdUEkPjmfhewFNgEPOvuG8zsQTObC2Bm080sDswDHjWzDYlz6wiaf35tZusBAx5LFP1MYtt6YBDwfzr3rUmXqFgJBUODewANzukPeflQFQ8vLhFps7TuAbj7Encf4+7nu/u3E9vud/cXE89XuXuJu/dx94HuPj7p3Nfd/RJ3n+jut7r7qcT2yxPbJrj7Leoh1E2Urwy+/ScvPWeWGAugGoB0f/Pnzz9tGoYHHniA73//+xw9epQrrriCqVOnMnHiRF544YVWy2pu2uhU0zo3NwV0V1KfPUnf4Qo4Eodz/+bMfRoLIF3hlfmwd33nljlsIsx5uNndN954I1/96le58847AXj22WdZunQp+fn5PP/888RiMQ4cOMDMmTOZO3dui+vwppo2ur6+PuW0zqmmgO5qSgCSvvLEAjDJ7f8NYkV/2i/SjU2ZMoX9+/eze/duKisr6d+/PyNGjKCmpob77ruPFStWkJOTw65du9i3bx/Dhg1rtqxU00ZXVlamnNY51RTQXU0JQNJX8Sb0igXz/jQVK4Lq3UE30RzNMSidpIVv6l1p3rx5LF68mL179zZOuvbMM89QWVnJ6tWr6dGjB6NGjUo5DXSDdKeNDpP+UiV95SthxEcgJ/fMfbHiYHroYxqrId3fjTfeyKJFi1i8eDHz5s0DgqmbhwwZQo8ePVi2bBnl5eUtltHctNHNTeucagrorqYEIOk5djAYA3BuiuYfSBoMpp5A0v2NHz+e6upqiouLGT58OAA333wzZWVlTJw4kaeffpqLL764xTKamza6uWmdU00B3dXUBCTpaVgAPnkEcLLGwWC7oXhaZmIS6UINN2MbDBo0iJUrU9/nOnr0zE6MvXr14pVXXkl5/Jw5c5gzZ85p2woKCk5bFCYTVAOQ9FSshNxeUDw19X5NByHS7SgBSHrK3wy+2ec1M2df74GQ21PTQYh0I0oA0roPjwZrADTX/g9Bz5/C4aoBSKfoTisVRklb/92UAKR18VXBdM/Ntf836FuiBCAdlp+fz8GDB5UE2sjdOXjwIPn5+Wmfo5vA0rqKlWA5MCLlhK1/EiuCnX/ITExy1iopKSEej6Pp39suPz+fkpKStI9XApDWlb8JQydAfqzl42JFUL1Hg8GkQ3r06NE4Sla6lv5KpWW1p4IF4M9tpfkHgp5Adafg+MGuj0tEOkw1AGnZnneg9kTq+X+aSl4YpqD9i/ecrKnjtqfLqK1zLhpWyMXDChkzrJCLhhbSp5d+ZUU6i/6apGUViQVg0qoBJA0GK5rc7kv+7Pfv87utB5hQHOPZsp0cP1XXuG/EgHO4aGghFw0r5KJhMS4eVsjoQX3okavKrEhbKQFIy8pXwoDzoWBI68c2DgZr/1iA/UdOsmDZNq4aN5SFf1VKfb0TP3SCzXuP8Md91WzeW82WvdUs21JJXX3QS6RHrnH+4AIuGlbImKFBjeGiYYUU9zunxal6RbKdEoA0r2EB+LHXpHd8nyGQk9ehrqCPLN1CTV099109FoCcHGPkwN6MHNibq8b/adrdD2vr2F55jC17g6Twx33VlO04xAtr/3Ttgl55jBla0FhTGDO0kAuGFNAzT7UF6X4KeuWRm9O5X2iUAKR5lZvh5OHW+/83yMmBwqJ21wDWx6tYvCbO7bPOY9SgPi0e2ysvl7HDY4wdfnrPpCMna9iaVFPYvLeaJev38Ms/VLQrJpGoeOPuj3PBkM5de1gJQJrX2P6fxg3gBu1cGtLdefDlDQzo3ZM7L7+gzec3Xj6/B9POHcC0cwecVvb+6g/ZvLeaHQeOUVuvAUbS/Qwq6NnpZSoBSPPKVwbTO/RvQ5/sWBHsWdvmS/3n+j2s2nGIf/r0RGL5Pdp8fkvMjKGxfIbG8vn4mPb3ThI526gxVFJzD9r/my4A35qGGkAbhvGfrKnjn5ZsZuzwGJ8tHdGOYEWkPZQAJLXDFUFbfjrdP5PFiqH2JJxIfzWjx3+3nV2HT/AP14zt9JtcItI8JQBJraKFBeBb0rdtXUH3HTnJT5a/x6fGD+XPzh/UtmuJSIcoAUhq5W9Cfl8YMq5t5zWMBahKLwF879Ut1NY5f3d1G68jIh2mBCCpVayEETPbPqlb8nQQrXhn52GeWxPnrz82mpEDe7cjSBHpCCUAOdOxA3Dgj23r/tmgYChYbqtdQYNunxsZVNCLO//8/HYGKiIdoQQgZ2ptAfiW5ORC4bBWE8BL6/awuvwQ93xqDIWd3O1TRNKjBCBnKl8JeflQNKV958daHg18sqaOh5dsYtzwGDdMU7dPkbCklQDMbLaZbTGzbWY2P8X+y8xsjZnVmtkNTfaNNLPXzGyTmW00s1GJ7aPN7L8TZf67mXX+MDdpn4o3obgU8tr5XxIrbrEGsHDFdnZXneT+a8ep26dIiFpNAGaWCywA5gDjgJvMrGmXjQrgVuAXKYp4GnjE3ccCM4D9ie3fBX7o7hcAh4AvtecNSCf78CjsWde+9v8GDQkgxWCwvVUn+bfl7zFnwjBmnjewA4GKSEelUwOYAWxz9+3ufgpYBFyXfIC773D3dUB98vZEoshz99cTxx119+MWzNF7ObA4cehTwPUdeifSOeJ/SCwA35EEUAQ1x4KJ5Jr43qubqav3xtk+RSQ86SSAYmBn0ut4Yls6xgCHzexXZva2mT2SqFEMBA67e207ypSuVJ7mAvAtSV4YJsnbFYf41du7+NKs0YwYoG6fImHr6pvAecAs4OvAdOA8gqaitJnZ7WZWZmZllZWVnR+hnK5iJQy7BHoVtr+MxoVh/pQATu/22f7ZPkWk86STAHYByV01ShLb0hEH1iaaj2qB/wCmAgeBfmbWMBtps2W6+0J3L3X30sGDNZNjl6o9BfFVbZ//p6kUg8FefGc3b1cc5hufuogCresrEgnpJIBVwIWJXjs9gc8BL6ZZ/iqCD/qGT+7LgY3u7sAyoKHH0BeAF9IPW7rEnrXBRG4daf+HYBwA1lgDOHGqjodf2cz4ohg3TCvpcJgi0jlaTQCJb+53AUuBTcCz7r7BzB40s7kAZjbdzOLAPOBRM9uQOLeOoPnn12a2HjDgsUTR9wJ3m9k2gnsCP+vctyZtVp5YAKajCSC3R2IwWFADeHTFe+ypOsk/XjueHHX7FImMtOri7r4EWNJk2/1Jz1cRNOOkOvd14JIU27cT9DCSqKhYCQMvhIJOaGqLFUHVLvZUneCnv32Pv5g4nBmjB7R+nohkjEYCS6C+Hire6lj//2SJhWG++8pm6h3mz7m4c8oVkU6jBCCByk1tWwC+NbFi6qp28R9rd3Obun2KRJISgATK27EAfAvqC4vIrTnKqII67viEun2KRJESgAQqVkJhEfQ7t1OKW30oH4D5l8boo26fIpGkBCDBnD3lK4Nv/21ZAL4Zx0/V8vg7NQBcVVLX4fJEpGsoAQgcLofq3R3v/pnw099uZ8OxAgByqtMdMygimaYEIMG3f+j4CGBg1+ETPPrb95g2ITHZWysLw4hIeJQAJJj/P78fDO74DJ3ffWUzAPdcPRH6DElrbWARCYcSgAQ1gJHtWAC+idXlH/DiO7u5/bLzKOnfu3EsgIhEkxJAtjtaCQe3drj9v77eefCljQwp7MWXP55Y5L2VlcFEJFxKANmuonPa/59/exfvxKu4d/bFf+r22bdYTUAiEaYEkO0qVkLeOTB8cruLOPZhLd9buplJJX35H1OS1vWJFcHJqmCZSRGJHCWAbFf+JpR0YAF44Ke/fY99Rz7k/mvHnT7bZ4qFYUQkOpQAstmH1bB3XYfa/+OHjrNwxXbmTipi2rlNZvtMsTCMiESHEkA22/kH8PoOzf/z8CubMYN7U8322czawCISDUoA2axiJVgulLRvWYayHR/w8ro93D7rPIr7nXPmAYVKACJRpgSQzcpXwvBLoFdBm0+tr3e+9dJGhsXy+fInzk99UI986D1QTUAiEaUEkK1qP4RdZe2e//+5NXHW76ri3jkX0btnC7N9aiyASGQpAWSr3WuDBeDb0f4fdPvcwqQR/bhuUnHLB8c0FkAkqpQAslVF+xeA/8nybVRWf8g/Nu32mUqsSAlAJKKUALJV+UoYNAb6DGrTaTs/OM5jv3uf6yYXMXVk/9ZPiBXBiUNw6ng7AxWRrqIEkI3q62HnW+369v/wK5vJMbh3dpqLvDcMBqve0+ZriUjXUgLIRvs3BlM0tHH+nz+8/wH/uX4PX/74+RSl6vaZigaDiUSWEkA2apgArg01gPp658GXNzC8bz7/67Jmun2m0rckeFRPIJHIUQLIRuVvBk0z/UamfcriNXHe3XWE+XMu5pyeuelfq3B48KgagEjkKAFkG/egBjAy/QXgj35YyyNLtzBlZD/mTipq2/V69oZz+kOVEoBI1CgBZJtDO4Ibsm3o/79gWUO3z/FYmknjNBoMJhJJSgDZprH9P70bwDs/OM7Pfvc+n55SzOQR/dp3TY0FEImktBKAmc02sy1mts3M5qfYf5mZrTGzWjO7ocm+OjNbm/h5MWn7k2b2ftK+yR1+N9K68oYF4NPrxvmdJZvIzTG+kW63z1S0NrBIJLUwiUvAzHKBBcCVQBxYZWYvuvvGpMMqgFuBr6co4oS7T26m+HvcfXGbIpaOaWj/T2MB+Le2H+SVd/dy95VjGNY3v/3XjJXA8QNQczKYIE5EIiGdGsAMYJu7b3f3U8Ai4LrkA9x9h7uvA+q7IEbpLEf3w8FtabX/1yUWeS/qm89ts87r2HUbxgJoMJhIpKSTAIqBnUmv44lt6co3szIze8vMrm+y79tmts7MfmhmvVKdbGa3J84vq6ysbMNl5QxtaP9fvHonG/ccYf7VY9vW7TMVDQYTiaRM3AQ+191Lgc8D/2xmDaOIvglcDEwHBgD3pjrZ3Re6e6m7lw4ePDgD4Z7FyhsWgJ/U4mHVJ2t4ZOkWpp3bn2svGd7x62ptYJFISicB7AJGJL0uSWxLi7vvSjxuB5YDUxKv93jgQ+DnBE1N0pUq0lsAfsGy9zhw9BT3XzOufd0+m4ppMJhIFKWTAFYBF5rZaDPrCXwOeLGVcwAws/4NTTtmNgi4FNiYeD088WjA9cC7bY5e0nfyCOxd3+r8P+UHj/HE79/nM1NLmNTebp9N9SqEXn1VAxCJmFZ7Abl7rZndBSwFcoEn3H2DmT0IlLn7i2Y2HXge6A9ca2bfcvfxwFjgUTOrJ0g2Dyf1HnrGzAYDBqwFvtzZb67R7rVw/GCXFd8t7NsQLADfyvw/31myibxc4xuzL+rc66srqEjktJoAANx9CbCkybb7k56vImgaanrem8DEZsq8vE2RdsSyb8PW1zJ2ucjKOwdKpje7+833DrB0wz6+ftUYhsY6ubtmX60MJhI1aSWAbu/Kh2BWqiEKWaZgSLMLwNfVOw+9vInifufwPzva7TOVWBHsWdf55YpIu2VHAhjSgVGsWeLZsp1s2nOEH39+Cvk9OtjtM5VYMRzbD7WnWr0JLSKZobmAhCMna/j+0i1MH9Wfv5jYCd0+U9FgMJHIUQIQFvxmGx8cP8X917Rzts90NA4G041gkahQAshyOw4c44n/ep8bppYwsaRv112ocTCYbgSLRIUSQJb7zpJN9MzN4Z5PdXK3z6Y0GlgkcpQAstib2w7w2sZ93PHnFzCks7t9NpUfg56FSgAiEaIEkKXq6p0HX95ISf9z+NLHRmfmorEiOBLPzLVEpFVKAFlq0aoKNu+t5r6rx3ZNt89UNBpYJFKUALJQ1YkafvDaH5kxegBzJgzL3IW1NrBIpCgBZKEf/2Yrh4534myf6YoVQfVeqKvJ3DVFpFlKAFnm/QPHePLNHXx22ggmFHdht89U+hYDDkf3Zfa6IpKSEkCW+fZ/bqJXXi5f+9SYzF9cXUFFIkUJIIv8fusB3ti0jzv//AKGFIawOHvDaOAq9QQSiQIlgCxRW1fPQy9vZMSAc/jipaPCCULTQYhESlbMBvq3i97mv7YdCDuMUNXWO4eP1/DTW6ZmrttnU/n9oEdvJQCRiMiKBDDt3P4U9MqKt9qiC4YU8KnxGez22ZRZYiyA5gMSiYKs+FT8q4+OCjsEaaDBYCKRoXsAklmxEiUAkYhQApDMihUFi8LU14UdiUjWUwKQzIoVgddpMJhIBCgBSGZpMJhIZCgBSGY1jgVQTyCRsCkBSGapBiASGUoAklm9B0BevmoAIhGgBCCZ1TgYTDUAkbApAUjmxYqhSjUAkbApAUjmqQYgEglpJQAzm21mW8xsm5nNT7H/MjNbY2a1ZnZDk311ZrY28fNi0vbRZvbfiTL/3cx6dvztSLcQK4Lq3VBfH3YkIlmt1QRgZrnAAmAOMA64yczGNTmsArgV+EWKIk64++TEz9yk7d8FfujuFwCHgC+1I37pjmLFUF8LxyrDjkQkq6VTA5gBbHP37e5+ClgEXJd8gLvvcPd1QFpf6SxYiPZyYHFi01PA9ekGLd1cY1dQ3QcQCVM6CaAY2Jn0Op7Ylq58Myszs7fM7PrEtoHAYXevba1MM7s9cX5ZZaW+MZ4VtDCMSCRkYjroc919l5mdB/zGzNYDVeme7O4LgYUApaWl3kUxSiapBiASCenUAHYBI5JelyS2pcXddyUetwPLgSnAQaCfmTUkoDaVKd1c74GQ21MJQCRk6SSAVcCFiV47PYHPAS+2cg4AZtbfzHolng8CLgU2ursDy4CGHkNfAF5oa/DSTeXkQOFwNQGJhKzVBJBop78LWApsAp519w1m9qCZzQUws+lmFgfmAY+a2YbE6WOBMjN7h+AD/2F335jYdy9wt5ltI7gn8LPOfGMScbFiJQCRkKV1D8DdlwBLmmy7P+n5KoJmnKbnvQlMbKbM7QQ9jCQbxYpgV1nYUYhkNY0ElnD0TdQAXPf1RcKiBCDhiBVD3Sk4fjDsSESylhKAhKNhLEBVPNw4RLKYEoCEQ4PBREKnBCDh0GAwkdApAUg4+gyGnDzVAERCpAQg4cjJhUKtCyASJiUACU+sSE1AIiFSApDwKAGIhEoJQMLTsDSkBoOJhEIJQMITK4bak3DiUNiRiGQlJQAJT+NYADUDiYRBCUDC0zcxf6B6AomEQglAwqMagEiolAAkPAVDwXJVAxAJiRKAhCcnFwqHQZVqACJhUAKQcGksgEholAAkXDFNByESFiUACVdMK4OJhEUJQMIVK4aaY3CyKuxIRLKOEoCESwvDiIRGCUDCpYVhREKjBCDh0mAwkdAoAUi4CocBpiYgkRAoAUi4cnsEI4JVAxDJOCUACV/fYtUAREKgBCDh02AwkVAoAUj4YsWaD0gkBGklADObbWZbzGybmc1Psf8yM1tjZrVmdkOK/TEzi5vZj5O2LU+UuTbxM6Rjb0W6rVgRnKqGk0fCjkQkq7SaAMwsF1gAzAHGATeZ2bgmh1UAtwK/aKaYh4AVKbbf7O6TEz/7045azi6NYwHUDCSSSenUAGYA29x9u7ufAhYB1yUf4O473H0dUN/0ZDObBgwFXuuEeOVspLEAIqFIJwEUAzuTXscT21plZjnAD4CvN3PIzxPNP/9gZtZMGbebWZmZlVVWVqZzWeluVAMQCUVX3wS+A1ji7vEU+25294nArMTPX6YqwN0Xunupu5cOHjy4C0OV0BQODx6VAEQyKi+NY3YBI5JelyS2peOjwCwzuwMoAHqa2VF3n+/uuwDcvdrMfkHQ1PR0+qHLWSOvJ/QZoiYgkQxLJwGsAi40s9EEH/yfAz6fTuHufnPDczO7FSh19/lmlgf0c/cDZtYDuAZ4o63By1lEK4OJZFyrTUDuXgvcBSwFNgHPuvsGM3vQzOYCmNl0M4sD84BHzWxDK8X2Apaa2TpgLUFieaz9b0O6vZhGA4tkWjo1ANx9CbCkybb7k56vImgaaqmMJ4EnE8+PAdPaFqqc1WJFUP77sKMQySoaCSzRECsKVgX78GjYkYhkDSUAiYa+iQpk9Z5w4xDJIkoAEg0aDCaScUoAEg0NCUCTwolkjBKAREOhFocXyTQlAImGHvnQe6CagEQySAlAokMLw4hklBKAREesRAlAJIOUACQ6NB2ESEYpAUh0xIrgxAdQcyLsSESyghKARIfWBRDJKCUAiQ4NBhPJKCUAiQ7VAEQySglAokM1AJGMUgKQ6OjZG87prxqASIYoAUi0aGEYkYxRApBoiRVBVTzsKESyghKARIumgxDJGCUAiZZYMRw/ADUnw45E5KynBCDR0tATSCuDiXQ5JQCJFo0FEMkYJQCJFiUAkYxRApBoiQ0PHo+oJ5BIV1MCkGjpVQi9+qoGIJIBSgASPeoKKpIRSgASPVoYRiQjlAAkevpqOgiRTFACkOiJFcPR/VB7KuxIRM5qaSUAM5ttZlvMbJuZzU+x/zIzW2NmtWZ2Q4r9MTOLm9mPk7ZNM7P1iTJ/ZGbWsbciZ41YEeBwdG/YkYic1VpNAGaWCywA5gDjgJvMbFyTwyqAW4FfNFPMQ8CKJtv+DbgNuDDxMzvtqOXs1jAauEr3AUS6Ujo1gBnANnff7u6ngEXAdckHuPsOd18H1Dc92cymAUOB15K2DQdi7v6WuzvwNHB9u9+FnF0aB4MpAYh0pbw0jikGdia9jgMfSadwM8sBfgDcAnyySZnJI33iiW2pyrgduB1g5MiR6VxWuruGGsDS+2DFI+HGIhIVNy2CAaM7tch0EkBH3AEscfd4e5v43X0hsBCgtLTUOzE2iar8vjDra3BwW9iRiERHXq/OLzKNY3YBI5JelyS2peOjwCwzuwMoAHqa2VHgXxLltKdMyQZX3B92BCJnvXQSwCrgQjMbTfAh/Tng8+kU7u43Nzw3s1uBUnefn3h9xMxmAv8N/BXwr20LXUREOqLVm8DuXgvcBSwFNgHPuvsGM3vQzOYCmNl0M4sD84BHzWxDGte+A3gc2Aa8B7zSzvcgIiLtYEEnnO6htLTUy8rKwg5DRKRbMbPV7l7adLtGAouIZCklABGRLKUEICKSpZQARESylBKAiEiW6la9gMysEihv5+mDgAOdGE5X607xKtau053i7U6xQveKt6Oxnuvug5tu7FYJoCPMrCxVN6io6k7xKtau053i7U6xQveKt6tiVROQiEiWUgIQEclS2ZQAFoYdQBt1p3gVa9fpTvF2p1ihe8XbJbFmzT0AERE5XTbVAEREJIkSgIhIlsqKBGBms81si5ltM7P5YcfTHDMbYWbLzGyjmW0ws78NO6bWmFmumb1tZi+HHUtrzKyfmS02s81mtsnMPhp2TM0xs/+d+B1418x+aWb5YceUzMyeMLP9ZvZu0rYBZva6mW1NPPYPM8ZkzcT7SOJ3YZ2ZPW9m/UIMsVGqWJP2fc3M3MwGdca1zvoEYGa5wAJgDjAOuMnMxoUbVbNqga+5+zhgJnBnhGNt8LcE60R0B/8CvOruFwOTiGjcZlYM/A3BAkoTgFyChZii5ElgdpNt84Ffu/uFwK8Tr6PiSc6M93VggrtfAvwR+Gamg2rGk5wZK2Y2ArgKqOisC531CQCYAWxz9+3ufgpYBFwXckwpufsed1+TeF5N8AFVHG5UzTOzEuAvCBb2iTQz6wtcBvwMwN1PufvhUINqWR5wjpnlAb2B3SHHcxp3XwF80GTzdcBTiedPAddnMqaWpIrX3V9LLHgF8BanL1Mbmmb+bQF+CHwD6LSeO9mQAIqBnUmv40T4Q7WBmY0CphAsmRlV/0zwC1kfchzpGA1UAj9PNFk9bmZ9wg4qFXffBXyf4JveHqDK3V8LN6q0DHX3PYnne4GhYQbTRn9NhFclNLPrgF3u/k5nlpsNCaDbMbMC4Dngq+5+JOx4UjGza4D97r467FjSlAdMBf7N3acAx4hWE0WjRNv5dQRJqwjoY2a3hBtV23jQv7xb9DE3s78jaH59JuxYUjGz3sB9wP2dXXY2JIBdwIik1yWJbZFkZj0IPvyfcfdfhR1PCy4F5prZDoJmtcvN7P+FG1KL4kDc3RtqVIsJEkIUfRJ4390r3b0G+BXwZyHHlI59ZjYcIPG4P+R4WmVmtwLXADd7dAdFnU/wZeCdxN9bCbDGzIZ1tOBsSACrgAvNbLSZ9SS4mfZiyDGlZGZG0Ea9yd3/b9jxtMTdv+nuJe4+iuDf9DfuHtlvqe6+F9hpZhclNl0BbAwxpJZUADPNrHfid+IKInrDuokXgS8knn8BeCHEWFplZrMJmjDnuvvxsONpjruvd/ch7j4q8fcWB6Ymfqc75KxPAImbPHcBSwn+iJ519w3hRtWsS4G/JPg2vTbxc3XYQZ1FvgI8Y2brgMnAd8INJ7VELWUxsAZYT/B3GqlpC8zsl8BK4CIzi5vZl4CHgSvNbCtBLebhMGNM1ky8PwYKgdcTf2s/DTXIhGZi7ZprRbfWIyIiXemsrwGIiEhqSgAiIllKCUBEJEspAYiIZCklABGRLKUEICKSpZQARESy1P8HvkTzV23+QwEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN + SVM model does not preform well under training. Therefore in the next chapter where going to look at regual SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(tensorflow_data_path +'models/model_CNN_v3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Normal SVM\n",
    "Loading the images and labels into memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    label = row['Emotion']\n",
    "    path = row['image_path']\n",
    "    img_array=cv2.imread(path)\n",
    "    img_array = img_array/255 #normalize    \n",
    "    training_data.append([img_array,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "lenofimage = len(training_data)\n",
    "\n",
    "\n",
    "for categories, label in training_data:\n",
    "    X.append(categories)\n",
    "    y.append(label)\n",
    "X= np.array(X).reshape(lenofimage,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='linear',gamma='auto')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model as a pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tensorflow_data_path + 'model_pkl', 'wb') as files:\n",
    "    pickle.dump(svc, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating the model score with a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on unknown data is 0.9723684210526315\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on unknown data is\",accuracy_score(y_test,y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a accuracy score of 0.9723684210526315 on the validating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on unknown data is               precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.95      0.97      0.96       115\n",
      "        Calm       1.00      1.00      1.00       109\n",
      "     Disgust       1.00      1.00      1.00       103\n",
      "        Fear       0.94      0.93      0.93       120\n",
      "       Happy       1.00      1.00      1.00        98\n",
      "         Sad       1.00      1.00      1.00       102\n",
      "    Surprise       0.93      0.93      0.93       113\n",
      "\n",
      "    accuracy                           0.97       760\n",
      "   macro avg       0.97      0.97      0.97       760\n",
      "weighted avg       0.97      0.97      0.97       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on unknown data is\",classification_report(y_test,y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final look at all of the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disgust</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calm</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angry</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disgust</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Calm</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Surprise</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Disgust</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Fear</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Happy</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     original predicted\n",
       "0     Disgust   Disgust\n",
       "1        Calm      Calm\n",
       "2       Angry     Angry\n",
       "3     Disgust   Disgust\n",
       "4       Happy     Happy\n",
       "..        ...       ...\n",
       "755      Calm      Calm\n",
       "756  Surprise  Surprise\n",
       "757   Disgust   Disgust\n",
       "758      Fear      Fear\n",
       "759     Happy     Happy\n",
       "\n",
       "[760 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'original' : y_test,'predicted' : y2})\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion \n",
    "The CNN + SVM model did not preform well, the network had a hard time correctly categorizing the images to the right label. On the other hand,  \n",
    "the regular SVM model performs really well, with emotion classification, with an accuracy score on unknown data of ≈0.97. <br>\n",
    "\n",
    "In short, the regular SVM model is a good choice for our emotion prediction system. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf3758f68ccd6a6ae59c6beb3af95554663b2df1117711160014e859fd9ca105"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
